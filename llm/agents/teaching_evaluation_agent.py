"""
æ•™å­¦è¯„ä»·æ™ºèƒ½ä½“
åŸºäºLLMå¯¹æ¨¡æ¿å†…å®¹è¿›è¡Œæ•™å­¦è¯„ä»·
"""

import json
import asyncio
import sys
import os
from typing import Dict, Any, Optional

# å°è¯•å¯¼å…¥loguruï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨æ ‡å‡†åº“logging
try:
    from loguru import logger
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

# å¤„ç†ç›¸å¯¹å¯¼å…¥å’Œç»å¯¹å¯¼å…¥
try:
    from ..modelscope_client import get_default_client
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    llm_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if llm_dir not in sys.path:
        sys.path.insert(0, llm_dir)
    from modelscope_client import get_default_client


class TeachingEvaluationAgent:
    """æ•™å­¦è¯„ä»·æ™ºèƒ½ä½“"""

    def __init__(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        self.llm_client = get_default_client()
        if not self.llm_client.is_configured():
            logger.warning("âš ï¸  LLMæœªé…ç½®ï¼Œæ•™å­¦è¯„ä»·å°†æ— æ³•ä½¿ç”¨")

    async def evaluate_teaching(self, text: str, template_id: str = None) -> Dict[str, Any]:
        """
        å¯¹æ¨¡æ¿å†…å®¹è¿›è¡Œæ•™å­¦è¯„ä»·

        Args:
            text: æ¨¡æ¿æ–‡æœ¬å†…å®¹
            template_id: æ¨¡æ¿IDï¼ˆå¦‚SY001ã€SY002ç­‰ï¼‰

        Returns:
            è¯„ä»·ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            {
                "evaluation": "è¯„ä»·å†…å®¹",
                "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2", ...],
                "improvements": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2", ...],
                "overall_score": è¯„åˆ†ï¼ˆ1-10ï¼‰
            }
        """
        if not self.llm_client.is_configured():
            logger.error("âŒ LLMæœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œæ•™å­¦è¯„ä»·")
            return {
                "evaluation": "LLMæœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œæ•™å­¦è¯„ä»·",
                "strengths": [],
                "improvements": [],
                "overall_score": 0
            }

        # æ ¹æ®æ¨¡æ¿ç±»å‹ç¡®å®šè¯„ä»·é‡ç‚¹
        template_info = self._get_template_info(template_id)
        
        # æ„å»ºæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¹¼å„¿æ•™è‚²ä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„è¯¾ç¨‹è®¾è®¡å’Œæ•™å­¦ç»éªŒã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹è¯¾ç¨‹æ¨¡æ¿è¿›è¡Œå…¨é¢ã€ä¸“ä¸šçš„æ•™å­¦è¯„ä»·ã€‚

è¯„ä»·ç»´åº¦åŒ…æ‹¬ï¼š
1. è¯¾ç¨‹ç›®æ ‡ï¼šç›®æ ‡æ˜¯å¦æ˜ç¡®ã€å…·ä½“ã€å¯è¾¾æˆ
2. æ•™å­¦å†…å®¹ï¼šå†…å®¹æ˜¯å¦é€‚åˆå¹¼å„¿å¹´é¾„ç‰¹ç‚¹ï¼Œæ˜¯å¦æœ‰è¶£å‘³æ€§å’Œæ•™è‚²æ€§
3. æ•™å­¦æ­¥éª¤ï¼šæ­¥éª¤æ˜¯å¦æ¸…æ™°ã€é€»è¾‘æ˜¯å¦åˆç†ã€æ˜¯å¦ä¾¿äºæ“ä½œ
4. æ•™å­¦æ–¹æ³•ï¼šæ–¹æ³•æ˜¯å¦å¤šæ ·ã€æ˜¯å¦èƒ½å¤Ÿæ¿€å‘å¹¼å„¿å…´è¶£
5. ææ–™å‡†å¤‡ï¼šææ–™æ˜¯å¦å……åˆ†ã€æ˜¯å¦å®‰å…¨ã€æ˜¯å¦ä¾¿äºè·å–
6. æ—¶é—´å®‰æ’ï¼šæ—¶é—´åˆ†é…æ˜¯å¦åˆç†
7. æ•´ä½“è®¾è®¡ï¼šè¯¾ç¨‹è®¾è®¡æ˜¯å¦å®Œæ•´ã€æ˜¯å¦æœ‰åˆ›æ–°ç‚¹

è¯·ä»ä¸“ä¸šè§’åº¦ç»™å‡ºå®¢è§‚ã€å»ºè®¾æ€§çš„è¯„ä»·ã€‚"""

        user_prompt = f"""è¯·å¯¹ä»¥ä¸‹è¯¾ç¨‹æ¨¡æ¿è¿›è¡Œä¸“ä¸šçš„æ•™å­¦è¯„ä»·ã€‚

æ¨¡æ¿ç±»å‹ï¼š{template_info['name']}
æ¨¡æ¿è¯´æ˜ï¼š{template_info['description']}

è¯¾ç¨‹å†…å®¹ï¼š
{text}

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä»·ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "evaluation": "æ€»ä½“è¯„ä»·ï¼ˆ200-300å­—ï¼ŒåŒ…æ‹¬è¯¾ç¨‹çš„æ•´ä½“è´¨é‡ã€è®¾è®¡æ€è·¯ã€é€‚ç”¨æ€§ç­‰ï¼‰",
    "strengths": [
        "ä¼˜ç‚¹1ï¼ˆè¯¾ç¨‹è®¾è®¡çš„äº®ç‚¹ï¼‰",
        "ä¼˜ç‚¹2",
        "ä¼˜ç‚¹3"
    ],
    "improvements": [
        "æ”¹è¿›å»ºè®®1ï¼ˆå¯ä»¥ä¼˜åŒ–çš„æ–¹é¢ï¼‰",
        "æ”¹è¿›å»ºè®®2",
        "æ”¹è¿›å»ºè®®3"
    ],
    "overall_score": è¯„åˆ†ï¼ˆ1-10åˆ†ï¼Œ10åˆ†ä¸ºæ»¡åˆ†ï¼‰
}}

è¦æ±‚ï¼š
1. è¯„ä»·è¦å®¢è§‚ã€ä¸“ä¸šã€æœ‰å»ºè®¾æ€§
2. ä¼˜ç‚¹è¦å…·ä½“ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
3. æ”¹è¿›å»ºè®®è¦å¯è¡Œã€æœ‰é’ˆå¯¹æ€§
4. è¯„åˆ†è¦åˆç†ï¼Œç»¼åˆè€ƒè™‘å„ä¸ªæ–¹é¢
5. åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—æˆ–è§£é‡Š

ç°åœ¨å¼€å§‹è¯„ä»·ï¼š"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        try:
            logger.info("ğŸ” å¼€å§‹ä½¿ç”¨LLMè¿›è¡Œæ•™å­¦è¯„ä»·...")
            
            # è°ƒç”¨LLM API
            result = await self.llm_client.call_api(
                messages,
                temperature=0.7,  # é€‚ä¸­çš„æ¸©åº¦ï¼Œä¿æŒåˆ›é€ æ€§
                response_format={"type": "json_object"},
                timeout=120,
                max_retries=3
            )

            if not result:
                logger.error("âŒ LLMè°ƒç”¨å¤±è´¥")
                return {
                    "evaluation": "LLMè°ƒç”¨å¤±è´¥ï¼Œæ— æ³•å®Œæˆè¯„ä»·",
                    "strengths": [],
                    "improvements": [],
                    "overall_score": 0
                }

            # è§£æç»“æœ
            if isinstance(result, dict):
                # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
                evaluation_result = {
                    "evaluation": result.get("evaluation", "è¯„ä»·å†…å®¹è§£æå¤±è´¥"),
                    "strengths": result.get("strengths", []),
                    "improvements": result.get("improvements", []),
                    "overall_score": result.get("overall_score", 0)
                }
                
                logger.info(f"âœ… æ•™å­¦è¯„ä»·å®Œæˆï¼Œè¯„åˆ†ï¼š{evaluation_result['overall_score']}/10")
                return evaluation_result
            else:
                logger.warning("âš ï¸  LLMè¿”å›æ ¼å¼å¼‚å¸¸")
                return {
                    "evaluation": "LLMè¿”å›æ ¼å¼å¼‚å¸¸",
                    "strengths": [],
                    "improvements": [],
                    "overall_score": 0
                }

        except Exception as e:
            logger.error(f"âŒ æ•™å­¦è¯„ä»·å‡ºé”™: {e}")
            return {
                "evaluation": f"è¯„ä»·è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}",
                "strengths": [],
                "improvements": [],
                "overall_score": 0
            }

    def _get_template_info(self, template_id: str) -> Dict[str, str]:
        """è·å–æ¨¡æ¿ä¿¡æ¯"""
        template_map = {
            "SY001": {
                "name": "èŠ‚åº†æ´»åŠ¨æ–¹æ¡ˆæ¨¡æ¿",
                "description": "ç”¨äºè®¾è®¡å„ç§èŠ‚åº†æ´»åŠ¨çš„è¯¾ç¨‹æ–¹æ¡ˆ"
            },
            "SY002": {
                "name": "ä½“é€‚èƒ½è¯¾æ¨¡æ¿",
                "description": "ç”¨äºè®¾è®¡å¹¼å„¿ä½“é€‚èƒ½è®­ç»ƒè¯¾ç¨‹"
            },
            "SY003": {
                "name": "ä¸»é¢˜æ´»åŠ¨é€šç”¨æ¨¡æ¿",
                "description": "ç”¨äºè®¾è®¡å„ç§ä¸»é¢˜æ´»åŠ¨çš„é€šç”¨æ¨¡æ¿"
            },
            "SY004": {
                "name": "ç»˜æœ¬å‰§æ¨¡æ¿",
                "description": "ç”¨äºè®¾è®¡åŸºäºç»˜æœ¬çš„æˆå‰§è¡¨æ¼”è¯¾ç¨‹"
            },
            "SY005": {
                "name": "é£Ÿè‚²è¯¾æ¨¡æ¿",
                "description": "ç”¨äºè®¾è®¡å¹¼å„¿é£Ÿè‚²æ•™è‚²è¯¾ç¨‹"
            }
        }
        
        if template_id and template_id in template_map:
            return template_map[template_id]
        else:
            return {
                "name": "é€šç”¨è¯¾ç¨‹æ¨¡æ¿",
                "description": "é€šç”¨è¯¾ç¨‹è®¾è®¡æ¨¡æ¿"
            }


async def evaluate_teaching_content(text: str, template_id: str = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¯¹è¯¾ç¨‹å†…å®¹è¿›è¡Œæ•™å­¦è¯„ä»·

    Args:
        text: è¯¾ç¨‹æ–‡æœ¬å†…å®¹
        template_id: æ¨¡æ¿ID

    Returns:
        è¯„ä»·ç»“æœå­—å…¸
    """
    agent = TeachingEvaluationAgent()
    return await agent.evaluate_teaching(text, template_id)


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    test_text = """
    è¯¾ç¨‹ç¼–å·ï¼šSY002-001
    è¯¾ç¨‹ç›®æ ‡ï¼š
    1. åŸ¹å…»å¹¼å„¿çš„èº«ä½“åè°ƒèƒ½åŠ›
    2. æé«˜å¹¼å„¿çš„è¿åŠ¨å…´è¶£
    3. å¢å¼ºå¹¼å„¿çš„å›¢é˜Ÿåˆä½œæ„è¯†
    
    è¯¾ç¨‹ææ–™ï¼š
    1. è½¯å«
    2. å°çƒ
    3. éŸ³ä¹æ’­æ”¾å™¨
    
    æ•™å­¦æ­¥éª¤ï¼š
    1. çƒ­èº«+å¼•å…¥
    æ¸¸æˆ1ï¼šå°åŠ¨ç‰©æ¨¡ä»¿
    ï¿® å¼•å¯¼å¹¼å„¿æ¨¡ä»¿å„ç§å°åŠ¨ç‰©çš„åŠ¨ä½œ
    ï¿® é€šè¿‡éŸ³ä¹èŠ‚å¥æ§åˆ¶åŠ¨ä½œé€Ÿåº¦
    ï¿® æŒ‡å¯¼è¯­ï¼šå°æœ‹å‹ä»¬ï¼Œæˆ‘ä»¬æ¥å­¦å°åŠ¨ç‰©èµ°è·¯å§ï¼
    """
    
    async def test():
        result = await evaluate_teaching_content(test_text, "SY002")
        print("è¯„ä»·ç»“æœï¼š")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    asyncio.run(test())

